{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.7' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/msys64/ucrt64/bin/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"retina_insights.csv\")\n",
    "data.drop(columns=[\"Unnamed: 0\"], inplace= True)\n",
    "data.columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[\"disc_area\"], data[\"cup_area\"], linestyle=\"\",marker=\"o\")\n",
    "sns.regplot(x=data[\"disc_area\"],y=data[\"cup_area\"])\n",
    "plt.xlabel(\"Disc area\")\n",
    "plt.ylabel(\"Cup area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[\"disc_diameter\"], data[\"cup_diameter\"], linestyle=\"\",marker=\"o\")\n",
    "sns.regplot(x=data[\"disc_diameter\"],y=data[\"cup_diameter\"])\n",
    "plt.xlabel(\"Disc diameter\")\n",
    "plt.ylabel(\"Cup diameter\")\n",
    "# sns.scatterplot(data=data[\"cup_diameter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_line(x,y):\n",
    "    m, c = np.polyfit(x, y, 1)\n",
    "    # print(m)\n",
    "    # print(c)\n",
    "    distances = []\n",
    "    for xi, yi in zip(x, y):\n",
    "        distance = abs(m * xi - yi + c) / np.sqrt(m**2 + 1)\n",
    "        distances.append(distance)\n",
    "    # print(distances)\n",
    "    distances = np.mean(distances)\n",
    "    # print(distances)\n",
    "    c_above = c + distances * np.sqrt(1 + m**2)\n",
    "    c_below = c - distances * np.sqrt(1 + m**2)\n",
    "    return m, c_below, c, c_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_position_parallel(m, c1, c2, c3, point):\n",
    "    x, y = point\n",
    "\n",
    "    # Sort intercepts to determine bottom, middle, and top lines\n",
    "    intercepts = sorted([(c1, \"Line 1\"), (c2, \"Line 2\"), (c3, \"Line 3\")])\n",
    "    bottom_line, middle_line, top_line = intercepts\n",
    "\n",
    "    # Calculate y-values for the given x-coordinate\n",
    "    y_bottom = m * x + bottom_line[0]\n",
    "    y_middle = m * x + middle_line[0]\n",
    "    y_top = m * x + top_line[0]\n",
    "\n",
    "    # Determine the position of the point relative to the lines\n",
    "    if y < y_bottom:\n",
    "        # return \"The point is below all the lines.\"\n",
    "        return 3\n",
    "    elif y > y_top:\n",
    "        # return \"The point is above all the lines.\"\n",
    "        return 0\n",
    "    elif y_bottom < y < y_middle:\n",
    "        # return f\"The point is between {bottom_line[1]} and {middle_line[1]}.\"\n",
    "        return 2\n",
    "    elif y_middle < y < y_top:\n",
    "        # return f\"The point is between {middle_line[1]} and {top_line[1]}.\"\n",
    "        return 1\n",
    "    else:\n",
    "        # return \"The point lies exactly on one of the lines.\"\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [\"autistic\", \"might be autistic\", \"might not be autistic\", \"not autistic\"]\n",
    "ref = [0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinaFundusDataset(Dataset):\n",
    "    def __init__(self, images_dir, annotations_dir=None, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.annotations_dir = annotations_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.images_dir, self.image_files[idx])\n",
    "\n",
    "        # Check if annotations are available\n",
    "        if self.annotations_dir:\n",
    "            annotation_name = os.path.join(self.annotations_dir, self.image_files[idx].replace('.jpg', '.json').replace('.png', '.json'))\n",
    "            # Load annotations (bounding boxes)\n",
    "            if os.path.exists(annotation_name):\n",
    "                with open(annotation_name, 'r') as f:\n",
    "                    annotations = json.load(f)\n",
    "\n",
    "                # Extract bounding boxes for optic disc and optic cup\n",
    "                disc_box = annotations['optic_disc']\n",
    "                cup_box = annotations['optic_cup']\n",
    "\n",
    "                # Extract height and width of the bounding boxes\n",
    "                disc_height = disc_box['height']\n",
    "                disc_width = disc_box['width']\n",
    "                cup_height = cup_box['height']\n",
    "                cup_width = cup_box['width']\n",
    "\n",
    "                # Targets: height and width of optic disc and optic cup\n",
    "                target = [disc_height, disc_width, cup_height, cup_width]\n",
    "            else:\n",
    "                target = torch.zeros(4)  # Default to zero if annotation file is missing\n",
    "        else:\n",
    "            # No annotations in test set\n",
    "            target = torch.zeros(4)  # Dummy target for test set, no annotations required\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(target, dtype=torch.float32)\n",
    "class RetinaModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RetinaModel, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 4)  # 4 outputs for height/width of optic disc and cup\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images_dir = 'testing_images'  # Replace with the path to your folder\n",
    "\n",
    "# Create dataset and dataloader for input images\n",
    "input_dataset = RetinaFundusDataset(input_images_dir, transform=transform)\n",
    "input_loader = DataLoader(input_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load the trained model\n",
    "model = RetinaModel()  # Ensure this is your trained model class\n",
    "model.load_state_dict(torch.load('retina_model.pth'))  # Load the saved model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "#function to check if the given data in an outlier\n",
    "\n",
    "# Evaluate the model on input images\n",
    "i=1\n",
    "with torch.no_grad():\n",
    "    for inputs, file_names in input_loader:\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Extract predicted bounding boxes (height, width)\n",
    "        disc_height, disc_width, cup_height, cup_width = abs(outputs[0])\n",
    "\n",
    "        # Calculate the area of optic disc and optic cup\n",
    "        disc_area = disc_height * disc_width\n",
    "        cup_area = cup_height * cup_width\n",
    "\n",
    "        # Display the results\n",
    "        # print(f\"Image: {file_names[0]}\")\n",
    "        print(f\"Image {i}:\")\n",
    "        i+=1\n",
    "        # print(f\"Optic Disc - Height: {disc_height:.2f}, Width: {disc_width:.2f}, Area: {disc_area:.2f}\")\n",
    "        # print(f\"Optic Cup - Height: {cup_height:.2f}, Width: {cup_width:.2f}, Area: {cup_area:.2f}\")\n",
    "        \n",
    "        #**DELETE**\n",
    "        #calculating the diameters and the areas\n",
    "        disc_diameter = (disc_height+disc_width)/2\n",
    "        cup_diameter = (cup_height+cup_width)/2\n",
    "        DiscArea = np.pi*(disc_diameter/2)**2\n",
    "        CupArea = np.pi*(cup_diameter/2)**2\n",
    "        \n",
    "        # classify=[DiscDiameterBound<=disc_diameter,CupDiameterBound<=cup_diameter,DiscAreaBound<=DiscArea,CupAreaBound<=CupArea]\n",
    "        # print(classify)\n",
    "        # print(disc_diameter,cup_diameter, DiscArea, CupArea)\n",
    "        #area\n",
    "        values = distance_line(data[\"disc_area\"], data[\"cup_area\"])\n",
    "        result1 = point_position_parallel(values[0], values[1], values[2], values[3], (DiscArea,CupArea))\n",
    "        \n",
    "        #diameter\n",
    "        values = distance_line(data[\"disc_diameter\"], data[\"cup_diameter\"])\n",
    "        result2 = point_position_parallel(values[0], values[1], values[2], values[3], (disc_diameter,cup_diameter))\n",
    "        if result1==result2:\n",
    "            print(answers[result2])\n",
    "        else:\n",
    "            print(answers[2])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
